

texts_da = {
    'intro': '''
Med kunstig intelligens er det muligt at ændre videoer og billeder, så det oprindelige indhold bliver erstattet af noget andet.
Det kalder man Deep Fake. Her kan du se nogle eksempler på Deep Fake videoer og selv lege med at styre en kendts ansigt.
YouTube kanalen "Daily Dose of Deepfake" viser her 80 af de bedste Deep Fakes.
''',
    'videos': '''
På fakeyou.com kan du lave dine egne små videoer, hvor en kendt person siger eller synger det, som du har optaget i en lydfil.
Vi har lavet nogle stykker, som du kan se her.

Tryk på knapperne for at bladre i videoerne.
    ''',
    'persons': '''
Her ser du billeder af nogle personer. Hvad har de til fælles?
    ''',
    'persons_explanation': '''
Grafikkort producenten Nvidia arbejdede i 2018 med at lave en kunstig
intelligens, der kunne afsløre falske billeder af ansigter. Under det
arbejde fandt de ud af, at man faktisk også kan få den samme kunstige
intelligens til at fremstille ansigter af mennesker,
der slet ikke eksisterer.

Faktisk viser undersøgelser at i 90% af tilfældene kan et menneske ikke afgøre, at der er tale om et falsk ansigt.

Kunne du spotte nogle falske ansigter?
Billederne har måske små fejl, der gør at du kan se at det er et falsk ansigt.
Meget ofte er der problemer med ansigtets symmetri og det er noget vi mennesker
er ret følsomme overfor. Specielt kan briller og øreringe se mærkeligt ud eller
sidde mærkeligt. Andre fejl, der tit optræder er mærkelige baggrunde,
specielt hvis der er mere end et ansigt i billedet. 
''',
    'camfun': '''
Nogle forskere arbejdede med at lære kunstig intelligens at bevæge et billede ud fra videooptagelser af en anden situation.
Det er der kommet denne lille sjove applikation ud af. Du kan styre nogle forskellige personer, som du burde kende,
ved at se ind i kameraet, få dit ansigt til at fylde den blå firkant og så trykke på knappen “Kalibrer billedet”.
Prøv at bevæge dig og tal, blink med øjnene, drej hovedet fra side til side.
Prøv også at ændre afstanden mellem kameraet og dit hovede.
Kan du se begrænsningerne i den kunstige intelligens? Det er ikke altid at resultatet ser super godt ud.

Denne software kan installeres på din PC og bruges til at ændre en optagelse af dig til noget andet,
når du f.eks. deltager i et Zoom møde eller er i Teams sammen med dine klassekammerater.
Hvis du vil hente det selv, så skal u nok være lidt skrap til engelsk og til PC’ere, men du kan
finde vejledningen på https://github.com/alievk/avatarify-desktop under Installation.
Du skal have en Gamer PC for grafikkortet bruges til beregningerne, der altså kræver en hel del,, når det skal være live video.
    ''',
    'outro': '''
Nu har du set nogle eksempler på hvordan man kan lave falske videoer og endda styre en anden person live
og dermed lave en falsk optræden på Zoom eller Teams. Det vi har vist her er harmløst og er bare sjov,
men i forbindelse med krigen i Ukraine har Rusland lavet en Deepfake med Ukraines præsident Zelensky,
hvor han siger til de Ukrainske styrker at de skal overgive sig og nedlægge våbnene. Den video var faktisk
ikke særligt god, så der er nok ingen, der ville tro på det uden lige at undersøge sagen nærmere.
Men nogle af de videoer du så på introduktionssiden er lavet super professionelt og kan være svære at afsløre
som falske. Nogle af dem kan du kun se er falske, fordi du ved, hvem der er den rigtige skuespiller i filmen.

Hvad nu hvis du ikke selv har lyst til at blive brugt i en Deepfake video?
Hvis du husker fra ‘Styr en kendt’, så havde teknologien nogle begrænsninger og den er ikke særligt god,
hvis det ikke er et portrætbillede, hvor man kigger lige i kameraet, man har af den, der skal styres.
Det samme gælder for deepfake videoer. Det virker bedst, hvis der er mange portrætbilleder. Deepfake videoerne
skal faktisk bruge rigtigt mange billeder af dig, for at lave noget, der er så overbevisende som dem i introvideoen.
Så overvej derfor hvor mange billeder og videoer du lægger af dig selv (og dine venner!) på sociale medier.
Prøv også at lave dine profilbilleder, så man altid ser dig fra siden.

Men hvad nu hvis nogen bruger et billede af dig til at lave en deepfake? Måske i en situation, som du slet ikke
har lyst til at andre skal se dig i. Hvad kan du så gøre?
For det første kan det være strafbart, så involver dine forældre eller andre voksne du stoler, f.eks. din spejderleder,
på og få det anmeldt til politiet. Mange forsikringsselskaber har også hjælp og dækning, hvis din digitale identitet
bliver misbrugt, så der kan der også være hjælp at hente. Sig også tydeligt til dem, du kender, at det er en deepfake
og du ikke har noget med det at gøre. Deepfaken er sikkert heller ikke særligt god, da det kræver mange timers arbejde
at lave en professionel deepfake, så du kan sikkert nemt pege på fejl i videoen, der viser det er en deepfake.

Men hvad så, hvis du i virkeligheden er blevet filmet i en situation, du helst ikke ville filmes i?
Så kan du jo påstå at det er en deepfake, nogen har lavet af dig!
''',
    'lets_start': 'Lad os komme igang!'
}


texts_en = {
    'intro': '''
By using Artificial Intelligence it is possible to change Videos and Pictures and replace the Original Content with something quite different.
This is called Deep Fake. Below You can see some examples of Deep Fake videos and later You can take control of a celebrity's face!
The YouTube Channel "Daily Dose of Deepfake' has collected 80 of the best Deep Fakes. 
''',
    'videos': '''
On the Website fakeyou.com it is possible to create Your own short Videos where a Celebrity says or sings what you have just recorded in a Soundfile.
We have made a few Videos which You can enjoy here.

Push the Buttons to scroll through the Videos.
    ''',
    'persons': '''

Here are some Pictures of different People. What do they have in common?
    ''',
    'persons_explanation': '''
Graphics Card Producer Nvidia research in 2018 how to make an Artificial
Intelligence that could detect pictures of fake faces. During te research
they found that it was possible to have the same Artificial Intelligence
create Pictures of Faces of People that simply does not exist.

Research show that in 90% of the Cases a Humans are not able to decide if they are seeing a fake face.  

Could You spot some Fake Faces?
The Picture often have small Errors which makes it possible to spot a Fake Face.
Very often there are Issues with the Symmetry of the Face and that is something
us Humans are very sensitive to. Especially Glasses and Ear Rings look weird or
are placed in wrong Positions. Other Error that frequently occurs are weird backgrounds,
especially if there are more than one Face in the Picture.
''',
    'camfun': '''
Nogle forskere arbejdede med at lære kunstig intelligens at bevæge et billede ud fra videooptagelser af en anden situation.
Det er der kommet denne lille sjove applikation ud af. Du kan styre nogle forskellige personer, som du burde kende,
ved at se ind i kameraet, få dit ansigt til at fylde den blå firkant og så trykke på knappen “Kalibrer billedet”.
Prøv at bevæge dig og tal, blink med øjnene, drej hovedet fra side til side.
Prøv også at ændre afstanden mellem kameraet og dit hovede.
Kan du se begrænsningerne i den kunstige intelligens? Det er ikke altid at resultatet ser super godt ud.

Denne software kan installeres på din PC og bruges til at ændre en optagelse af dig til noget andet,
når du f.eks. deltager i et Zoom møde eller er i Teams sammen med dine klassekammerater.
Hvis du vil hente det selv, så skal u nok være lidt skrap til engelsk og til PC’ere, men du kan
finde vejledningen på https://github.com/alievk/avatarify-desktop under Installation.
Du skal have en Gamer PC for grafikkortet bruges til beregningerne, der altså kræver en hel del,, når det skal være live video.
    ''',
    'outro': '''
Nu har du set nogle eksempler på hvordan man kan lave falske videoer og endda styre en anden person live
og dermed lave en falsk optræden på Zoom eller Teams. Det vi har vist her er harmløst og er bare sjov,
men i forbindelse med krigen i Ukraine har Rusland lavet en Deepfake med Ukraines præsident Zelensky,
hvor han siger til de Ukrainske styrker at de skal overgive sig og nedlægge våbnene. Den video var faktisk
ikke særligt god, så der er nok ingen, der ville tro på det uden lige at undersøge sagen nærmere.
Men nogle af de videoer du så på introduktionssiden er lavet super professionelt og kan være svære at afsløre
som falske. Nogle af dem kan du kun se er falske, fordi du ved, hvem der er den rigtige skuespiller i filmen.

Hvad nu hvis du ikke selv har lyst til at blive brugt i en Deepfake video?
Hvis du husker fra ‘Styr en kendt’, så havde teknologien nogle begrænsninger og den er ikke særligt god,
hvis det ikke er et portrætbillede, hvor man kigger lige i kameraet, man har af den, der skal styres.
Det samme gælder for deepfake videoer. Det virker bedst, hvis der er mange portrætbilleder. Deepfake videoerne
skal faktisk bruge rigtigt mange billeder af dig, for at lave noget, der er så overbevisende som dem i introvideoen.
Så overvej derfor hvor mange billeder og videoer du lægger af dig selv (og dine venner!) på sociale medier.
Prøv også at lave dine profilbilleder, så man altid ser dig fra siden.

Men hvad nu hvis nogen bruger et billede af dig til at lave en deepfake? Måske i en situation, som du slet ikke
har lyst til at andre skal se dig i. Hvad kan du så gøre?
For det første kan det være strafbart, så involver dine forældre eller andre voksne du stoler, f.eks. din spejderleder,
på og få det anmeldt til politiet. Mange forsikringsselskaber har også hjælp og dækning, hvis din digitale identitet
bliver misbrugt, så der kan der også være hjælp at hente. Sig også tydeligt til dem, du kender, at det er en deepfake
og du ikke har noget med det at gøre. Deepfaken er sikkert heller ikke særligt god, da det kræver mange timers arbejde
at lave en professionel deepfake, så du kan sikkert nemt pege på fejl i videoen, der viser det er en deepfake.

Men hvad så, hvis du i virkeligheden er blevet filmet i en situation, du helst ikke ville filmes i?
Så kan du jo påstå at det er en deepfake, nogen har lavet af dig!
''',
    'lets_start': 'Let\'s get started!'

}
